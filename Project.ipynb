{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb22622-99bf-46ef-96e8-3804f632c715",
   "metadata": {},
   "source": [
    "# ONS Census 2021 - PII Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06853d4-350c-46de-9c00-f68671b2c3b4",
   "metadata": {},
   "source": [
    "### Importing/Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "root = pathlib.Path(\"data\")\n",
    "\n",
    "region_sizes = {\"Country\" : \"ctry\",\n",
    "                \"Region\" : \"rgn\",\n",
    "                \"Upper-Tier Local Authority\" : \"utla\",      #153 in England\n",
    "                \"Lower-Tier Local Authority\" : \"ltla\",      #296 in England\n",
    "                \"Middle-Layer Super Output Area\" : \"msoa\",  #2000-6000 households; 5000-15000 persons\n",
    "                \"Lower-Layer Super Output Area\" : \"lsoa\",   #400-1200 households; 1000-3000 persons\n",
    "                \"Output Area\" : \"oa\"}                       #40-250 households; 100-625 persons\n",
    "\n",
    "region_indices = {3 : \"ctry\", #how many are per country\n",
    "                  10 : \"rgn\",\n",
    "                  174 : \"utla\",\n",
    "                  331 : \"ltla\",\n",
    "                  7264 : \"msoa\",\n",
    "                  35672 : \"lsoa\",\n",
    "                  188800 : \"oa\"}\n",
    "\n",
    "regions = list(region_sizes.values())\n",
    "\n",
    "def import_data(region : str, target_groups : list = None, target_codes: list = None): \n",
    "    '''Imports target census data\\n\n",
    "    Parameters:\\n\n",
    "        region, should be string of one of the following: ctry, rgn, utla, ltla, msoa, lsoa, oa\\n\n",
    "        target_groups, should be a list of strings of the descriptions of the data values as found at https://www.nomisweb.co.uk/census/2021/bulk\\n\n",
    "        target_codes, should be a list of strings of the codes of the data values as found at https://www.nomisweb.co.uk/census/2021/bulk\\n\n",
    "    Note: one of the two target parameters must be passed\\n\n",
    "\n",
    "    Returns dictionary of \"Data type code\" : Pandas DataFrame'''\n",
    "    if target_groups == None and target_codes == None:\n",
    "        raise ValueError(\"Need specified groups to import\")\n",
    "    \n",
    "    region = str(region)\n",
    "    if region not in regions:\n",
    "        regions_error = '\\n'.join(f\"{key}  :  {val}\" for key, val in region_sizes.items())\n",
    "        raise ValueError(f\"Region code must be one of the following: \\nRegion  :  Region Code\\n{regions_error}\")\n",
    "    \n",
    "    codes = pd.read_csv(root / \"census_codes.csv\")\n",
    "    codes[\"Filename\"] = (\n",
    "    codes[\"Filename\"].str.split(\".\")\n",
    "    .apply(lambda x: x[0])\n",
    "    )\n",
    "\n",
    "    if target_groups:\n",
    "        valid_target_groups = [group for group in target_groups if group in codes[\"Description\"].values]\n",
    "        if len(valid_target_groups) == 0:\n",
    "            raise ValueError(\"Inputs not found in code database, ensure the group names are as found on https://www.nomisweb.co.uk/census/2021/bulk\")\n",
    "        erroneous_groups = [group for group in target_groups if group not in valid_target_groups]\n",
    "        output_erroneous_groups = '\\n'.join(erroneous_groups)\n",
    "        if len(erroneous_groups) > 0:\n",
    "            warnings.warn(f\"The following groups were not imported as they are invalid: {output_erroneous_groups}\\nEnsure the group names are as found on https://www.nomisweb.co.uk/census/2021/bulk\")\n",
    "        \n",
    "    if target_codes:\n",
    "        valid_target_codes = [code for code in target_codes if code in codes[\"Code\"].values]\n",
    "        if len(valid_target_codes) == 0:\n",
    "            raise ValueError(\"Inputs not found in code database, ensure codes are in the form 'TSXXX' where X's are digits, as found on https://www.nomisweb.co.uk/census/2021/bulk\")\n",
    "        erroneous_codes = [code for code in target_codes if code not in valid_target_codes]\n",
    "        output_erroneous_codes = '\\n'.join(erroneous_codes)\n",
    "        if len(erroneous_codes) > 0:\n",
    "            warnings.warn(f\"The following codes were not imported as they are invalid: {output_erroneous_codes}\\nEnsure codes are in the form 'TSXXX' where X's are digits, as found on https://www.nomisweb.co.uk/census/2021/bulk\")\n",
    "    \n",
    "    if target_groups:\n",
    "        try:\n",
    "            valid_target_codes = valid_target_codes\n",
    "        except UnboundLocalError:\n",
    "            valid_target_codes = []\n",
    "        for group in valid_target_groups:\n",
    "            valid_target_codes.append(codes.loc[codes[\"Description\"] == group,\"Code\"].item())\n",
    "\n",
    "    data = {}\n",
    "    for code in valid_target_codes:\n",
    "        folder = codes.loc[codes[\"Code\"] == code, \"Filename\"].item()\n",
    "        try:\n",
    "            data.update({code : pd.read_csv(root / folder / f\"{folder}-{region}.csv\").drop(columns=\"date\")})\n",
    "        except FileNotFoundError:\n",
    "            warnings.warn(f\"File {folder}-{region}.csv not found in data/{folder}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def import_all_data(region : str):\n",
    "    '''Imports all installed census data\\n\n",
    "    Parameters:\\n\n",
    "        region, should be string of one of the following: ctry, rgn, utla, ltla, msoa, lsoa, oa\\n\n",
    "    Returns dictionary of \"Data type code\" : Pandas DataFrame\n",
    "    '''\n",
    "    region = str(region)\n",
    "    if region not in regions:\n",
    "        regions_error = '\\n'.join(f\"{key}  :  {val}\" for key, val in region_sizes.items())\n",
    "        raise ValueError(f\"Region code must be one of the following: \\nRegion  :  Region Code\\n{regions_error}\")\n",
    "\n",
    "    codes = pd.read_csv(root / \"census_codes.csv\")\n",
    "    codes[\"Filename\"] = (\n",
    "    codes[\"Filename\"].str.split(\".\")\n",
    "    .apply(lambda x: x[0])\n",
    "    )\n",
    "    \n",
    "    data = {}\n",
    "    for code in codes[\"Code\"].values:\n",
    "        folder = codes.loc[codes[\"Code\"] == code, \"Filename\"].item()\n",
    "        try:\n",
    "            data.update({code : pd.read_csv(root / folder / f\"{folder}-{region}.csv\").drop(columns=\"date\")})\n",
    "        except FileNotFoundError:\n",
    "            warnings.warn(f\"File {folder}-{region}.csv not found in data/{folder}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def cleanup_all(data : dict, remove_geography : bool = True, remove_geography_code : bool = True):\n",
    "    '''\n",
    "    Removes the specified columns from all dataframes\\n\n",
    "    Parameters:\\n\n",
    "        data, data to be cleaned, dictionary of \"Data type code\" : Pandas DataFrame\\n\n",
    "        remove_geography, whether to remove geography column, bool\\n\n",
    "        remove_geography-code, whether to remove geography code column, bool\\n\n",
    "        \n",
    "    Returns dictionary of \"Data type code\" : Pandas DataFrame\n",
    "    '''\n",
    "    for key in data.keys():\n",
    "        dataframe = data[key]\n",
    "        try:\n",
    "            if remove_geography:\n",
    "                dataframe = dataframe.drop(columns=\"geography\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            if remove_geography_code:\n",
    "                dataframe = dataframe.drop(columns=\"geography code\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "        data[key] = dataframe\n",
    "    return data\n",
    "\n",
    "def cleanup(dataframe, columns : list):\n",
    "    '''Removes specified columns from dataframe\\n\n",
    "    Parameters:\\n\n",
    "        dataframe, Pandas DataFrame to be cleaned\\n\n",
    "        columns, list of strings of column names to be removed\\n\n",
    "    '''\n",
    "    if type(columns) is not list:\n",
    "        raise ValueError(\"Parameter 'columns' must be a list\")\n",
    "    elif len([column for column in columns if type(column) is str]) == 0:\n",
    "        raise ValueError(\"Parameter 'columns' must be a list of strings\")  \n",
    "    for column in columns:\n",
    "        try:\n",
    "            dataframe = dataframe.drop(columns=column)\n",
    "        except KeyError:\n",
    "            warnings.warn(f\"Column {column} does not exist \")\n",
    "    return dataframe\n",
    "\n",
    "def factor_in_age(df, name=None):\n",
    "    df_age = import_data(region_indices[len(df.index)], target_codes=[\"TS004\"])[\"TS004\"]\n",
    "    df_age_totals_column = [column for column in list(df_age.columns) if \"Total\" in column][0]\n",
    "    df_totals_column = [column for column in list(df.columns) if \"Total\" in column][0]\n",
    "    if name is not None:\n",
    "        name = str(name)\n",
    "    else:\n",
    "        name = \"Not accounted for\"\n",
    "    df[name] = df_age[df_age_totals_column] - df[df_totals_column]\n",
    "    df[df_totals_column] = df_age[df_age_totals_column]\n",
    "    df.rename(columns={df_totals_column:\"Total\"}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01338000-ffd5-4701-ae53-698efdfd25e3",
   "metadata": {},
   "source": [
    "### Combining Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ba3cc-d61f-4242-9068-a97a53952735",
   "metadata": {},
   "source": [
    "This function takes an input of 2 data frames of population values. The 2 data frames get passed through the prob_calc function, and then iterated through and combined. The output is a table of combined probabilities.\n",
    "\n",
    "Data must be input in the form\n",
    "\n",
    "<table style=\"border-collapse:collapse;border-spacing:0\" class=\"tg\"><thead><tr><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Region<br></th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Population</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Variable 1</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</th></tr></thead><tbody><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North East</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">2647013</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:right;vertical-align:top;word-break:normal\">2536430</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North West</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">7417399</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">6885187</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr></tbody></table>\n",
    "\n",
    "<table style=\"border-collapse:collapse;border-spacing:0\" class=\"tg\"><thead><tr><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Region<br></th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Population</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Variable 2</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</th></tr></thead><tbody><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North East</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">2647013</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:right;vertical-align:top;word-break:normal\">2536430</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North West</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">7417399</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">6885187</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr></tbody></table>\n",
    "\n",
    "and output in the form\n",
    "\n",
    "<table style=\"border-collapse:collapse;border-spacing:0\" class=\"tg\"><thead><tr><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Region<br></th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Population</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">Probability of Var1 and Var2</th><th style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</th></tr></thead><tbody><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North East</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">2647013</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:right;vertical-align:top;word-break:normal\">2536430</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr><tr><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">North West</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">7417399</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">6885187</td><td style=\"border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\">...</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf8736-eefe-47b2-932f-3b3efd68f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_probability_tables(inputdata1, inputdata2):\n",
    "    df1 = prob_calc(inputdata1)\n",
    "    df2 = prob_calc(inputdata2)\n",
    "\n",
    "    \n",
    "    #create lists of characteristics in each table\n",
    "    df1_names = df1.columns.values.tolist()\n",
    "    df2_names = df2.columns.values.tolist()\n",
    "    \n",
    "    #create a new table to store the combined probabilities, our results\n",
    "    dfprobability = pd.DataFrame();\n",
    "    dfprobability[\"Region\"] = df1[df1_names[0]]\n",
    "    dfprobability[\"Total Population\"] = df1[df1_names[1]]\n",
    "    \n",
    "    del df1_names[:2]\n",
    "    del df2_names[:2]\n",
    "    \n",
    "    #nested for loop iterates through columns of both tables and multiplies them together \n",
    "    #output is a series which is then added to the reults table\n",
    "    for col1 in df1_names:\n",
    "        for col2 in df2_names:\n",
    "            s = df1[col1] * df2[col2]\n",
    "            dfprobability = pd.concat([dfprobability,s.rename(col1+\" and \" +col2)], axis=1)\n",
    "     \n",
    "    #output result\n",
    "    return dfprobability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e4a2c-8e4b-41ba-93d2-81dae4d2550a",
   "metadata": {},
   "source": [
    "We also looked at expanding this function to consider more than 2 characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec32a821-7c4e-4d05-ada2-1856bea03978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function takes an input of a list of characteristic codes. assumes data has been imported via import_data or import_all_data functions, \n",
    "#assmues geography code column has been removed by calling cleanup_all(data,False,True)\n",
    "def create_prob_table(list):\n",
    "    \n",
    "    count = 1\n",
    "    if len(list) < 2:\n",
    "        raise ValueError(\"Must input more than one characteristic\")\n",
    "    else:\n",
    "        for i in list:\n",
    "            if count == 1:\n",
    "                dfprobability = combineprobabilitytables(data[list[0]], data[list[1]])\n",
    "            elif count != len(list):\n",
    "                dfprobability = combineprobabilitytables(dfprobability, data[list[count]])\n",
    "        \n",
    "            count+= 1\n",
    "    \n",
    "\n",
    "    return dfprobability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8329551-fd04-4448-8cbf-0df4bc91600f",
   "metadata": {},
   "source": [
    "### Identifying Select Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189570fc-d83f-4900-9486-51f549ede5e4",
   "metadata": {},
   "source": [
    "### Probability Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616449ac-095a-4e69-a672-72346ebdd908",
   "metadata": {},
   "source": [
    "Function to calculate probailities as a percent of the total in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f6515-899a-4d86-b581-12015a04fdb7",
   "metadata": {},
   "source": [
    "Data must be input in the form\n",
    "\n",
    "| Region     | Population | Variable | ... |\n",
    "|------------|------------|----------|-----|\n",
    "| North East | 2647013    |  2536430 | ... |\n",
    "| North West | 7417399    | 6885187  | ... |\n",
    "\n",
    "and will be output in the form\n",
    "\n",
    "| Region     | Population | Probability | ... |\n",
    "|------------|------------|-------------|-----|\n",
    "| North East | 2647013    |    0.958223 | ... |\n",
    "| North West | 7417399    | 0.928248    | ... |  |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445cb6b6-dd5b-476a-84cd-f051b3fb69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_calc(dataframe):\n",
    "    probabilities = pd.DataFrame(dataframe)\n",
    "    total = dataframe.loc[:,dataframe.columns[1]]\n",
    "    \n",
    "    count = 2\n",
    "\n",
    "    # Iterates through columns in dataframe\n",
    "    for num in range(len(dataframe.columns)-2):\n",
    "        column = dataframe.loc[:,dataframe.columns[count]]\n",
    "        cell_count = 0\n",
    "        # Iterates through items in each column\n",
    "        for row in column:\n",
    "            #Divides current cell by the item at the start of the row\n",
    "            probabilities.loc[:, dataframe.columns[count]].at[cell_count] = row / total[cell_count]\n",
    "            cell_count += 1\n",
    "        count += 1\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88de6c-ba4b-44b1-9071-64ee764681e2",
   "metadata": {},
   "source": [
    "### Correlations in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0108b137-3185-4396-b3c7-883f629dd07b",
   "metadata": {},
   "source": [
    "### Visualising the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d70709-61a6-46c3-a22b-88f9715ed081",
   "metadata": {},
   "source": [
    "### Extension - Research how ONS privacy protection exercises have impacted the final results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0eca8-51ea-4d0b-96de-e33457096dcc",
   "metadata": {},
   "source": [
    "### Extension - Explore wider utility of the census data for other Hartree Centre projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2419bd9-e19a-44cb-b61e-4c34f5c2d3de",
   "metadata": {},
   "source": [
    "### Extension - Consider other open data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cad7e-7976-49a1-8b7c-6775dfae8481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
